# Билеты

## Билет №1: Понятие объекта. Представление объекта в памяти. Управление жизнью объекта. Выравнивание и padding.

### 1. Что такое объект. Представление объекта в памяти
- Объект прибит к последовательному участку памяти (automatic, static, dynamic, thread-local storage duration)
- Время жизни (`lifetime`):
    - Начало — вызов конструктора
    - Конец — вызов деструктора  
- Любой доступ вне времени жизни = **UB (undefined behavior)**.
- Копия или перемещение (`std::move`) = другой объект; объект не может переехать
- Объект занимает `sizeof(object)` байт непрерывной памяти.
- Каждый объект имеет `выравнивание (alignment)`, кратное `alignof(type)`.
- Объект имеет тип
- Объект имеет значение

### 2. Выравнивание
- Выравнивание гарантирует, что объект хранится по адресу, кратному требованиям архитектуры.
- Нарушение выравнивания → UB.
- Пример выравнивания:
  ```cpp
  struct S {
      int32_t a;  // 4-байтное выравнивание
      char b;     // 1-байтное
  };
  ```

### 3. Padding
- **Padding** — дополнительные байты между полями, чтобы соблюсти выравнивание.
- Пример:
  ```less
  Memory layout of S (sizeof(S) = 8):
  | a (4B) | b (1B) | pad | pad | pad |
  ```
- Без padding доступ к `a` и `b` мог бы быть неэффективным или вообще вызывать UB на некоторых архитектурах.
- Более подробный пример:
  ```cpp
  struct Example {
      char c;    // 1 байт
      int i;     // 4 байта, нужно выравнивание 4
  };
  ```
  ```less
  Адрес:   0   1   2   3   4   5   6   7
           +---+---+---+---+---+---+---+---+
  Память:  | c |pad|pad|pad| i0| i1| i2| i3|
           +---+---+---+---+---+---+---+---+
  sizeof(Example) = 8
  ```
- `pad` — байты, вставленные компилятором для выравнивания поля `i`.

### 4. Ручное управление временем жизни
- `placement new` позволяет создавать объект **по заранее выделенному адресу**.
- Пример:
```cpp
alignas(std::string) char buf[sizeof(std::string)];
new (buf) std::string("Hello");  // конструктор
reinterpret_cast<std::string*>(buf)->~basic_string();  // деструктор
```
- Для **тривиально разрушаемых объектов** деструктор вызывать не обязательно.

### 5. Тривиально и нетривиально разрушаемые объекты
- Объект **тривиально разрушаемый**, если:
  - Деструктор **не определён** или `= default`.
  - Деструктор **не выполняет пользовательской логики**.
- Вызов деструктора для них **не обязателен**.
- Примеры:
  ```cpp
  int x;          // тривиально разрушаемый
  double arr[10]; // тривиально разрушаемый

  std::string s;  // содержит динамическую память (нетривиально разрушаемый)
  class C {
      ~C() { /* логика */ }
  };  // нетривиально разрушаемый
  ```

### 6. Итог
- **Объект** = память (в какой хранится) + размер + выравнивание + тип + время жизни + значение + имя (опционально).
- **Выравнивание** и **padding** — важны для корректного и эффективного доступа к памяти.
- **Тривиально разрушаемые объекты** позволяют оптимизации: деструктор вызывать необязательно.
- **RAII** и понимание времени жизни объектов — фундамент безопасного C++.

---

## Билет №2: Виды памяти. Динамическая память. Разница между `malloc`, `operator new`, `new` и `new[]`. `SIOF`: что это, как бороться.

### 1. Виды памяти
- automatic storage duration (жаргон "на стеке")
- static storage duration (жаргон "глобальный", глобальные переменные)
- dynamic storage duration (жаргон "в куче", классический new)
- thread-local storage duration (C++11, после многопоточки; будем обсуждать только через 10 лекций)

### 2. Динамическая память (`dynamic storage duration`)
- выделяется и освобождается руками
- объекты живут столько, сколько напишет программист
- low-level сырые `operator new`, `malloc` (вовзращают указатель на блоки сырой памяти)
- high-level типизированный `new` expression (`new int`, `new char[32]`)
- обёртки вроде `std::vector`, `std::string`

Примеры использования:
```cpp
int* kek = new int{42};
delete kek;

int* array = new int[100];
delete[] array;

std::unique_ptr<int> ptr(new int{19});

// Calls operator new(sizeof(int) * 100)
std::vector<int> v(100);

std::unordered_map<int, int> x;
// Calls new std::pair<const int, int>(1, 2);
x[1] = 2;
```

```cpp
int* x = new int();
delete x;

int* arr = new int[100];
delete[] arr;
// delete arr - UB! Имеется в виду если без [] прописать

new int();
// Leak, but not UB. Memory leaks are safe
```
- за каждым `new` должен идти ровно один корректный `delete`
- `std::vector`, `std::unique_ptr`, другие контейнеры делают это в деструкторе
- Если нет `new`, значит нет и `delete`

Случай с `std::unique_ptr` немного некрасивый, в том плане, что мы зовём `new`, но не зовём `delete`. Поэтому специально для этого была реализована функция `std::make_unique`, которая под капотом зовёт `new`:
```cpp
// Вместо std::unique_ptr<int> ptr(new int{19}); пишем это
std::unique_ptr<int> ptr = std::make_unique(int(19));
```

`new int[]` выделяет сырые байты памяти, а затем в каждой ячейке вызывает конструктор. `delete[]` делает противоположное: пробегает по всем ячейкам, вызывая деструкторы, а затем уже освобождает саму память.

Вот эта штука - UB:
```cpp
#include <memory>

int main() {
    // [size[ ][ ][ ]]
    //      ^^^
    // Указатель смотрит на первый элемент, а размер, например игнорирует
    // То есть в итоге высвобождается не вся память
    // P.S. это просто пример, модель может быть и иной, но обычно это так и выглядит:
    // размер массива, потом сами элементы
    std::unique_ptr<int> ptr(new int[100]);
}
```

А вот уже корректный пример:
```cpp
std::unique_ptr<int[]> ptr(new int[100]);
```
Но вообще у `std::unique_ptr` есть второй шаблонный параметр: `deleter`. Через него можно закастомить `delete`.
```cpp
std::unique_ptr<int[], std::default_delete<int[]>> ptr(new int[100]);
```

На C нет удобных инструментов для работы с памятью. Управление ресурсами это каждый раз:
- `malloc` для выделения памяти
- `goto err` обработка каждой ошибки
- `free` для освобождения памяти

При таких вводных написание кода на C было и есть - боль. 

Рекомендации/приципы при работе с динамической памятью:
- не используйте `malloc`, `operator new`, `new expression` никогда!
  В основном они используются при написании low-level кода, например, при реализации собственных контейнеров.
  Но даже там лучше использовать `std::allocator<TypeName>`, и это даже рекомендуется, и считается хорошей практикой.
- используйте `std::unique_ptr` и `std::make_unique`, контейнеры
- использование `new` - моветон, так плохо писать код; скорее всего будут ошибки:
    - Проверяйте свой код при помощи Address Sanitizer

### 3. Автоматическая память (`automatic storage duration`)
```cpp
int x;
```
- Автоматически выделяет и освобождает память, никакой ручной работы.
- Почти всегда здесь память выделяется на стеке.
- Автоматическая память достаточно маленькая (2, 4, 8 Мб), поэтому используйте её для хранения указателей на динамическую память. Что-то большое хранить в автоматической памяти не получится.

### 4. Статическая память (`static storage duration`)
```cpp
static int y;
```
- Глобальные переменные, переменные, которые живут на протяжении всего исполнения программы.
- Меняющиеся глобальные переменные зло, но как и везде есть исключения. Сами по себе глобальные переменные занимают место в выходном бинарном файле.
- Константы, конечно, заводить можно.

### 5. `thread-local storage duration`
- Что-то типо локальной памяти конкретного потока
- `thread_local int counter = 0;` - теперь у каждого потока будет свой экземпляр `counter`. И они не зависят друг от друга
- Живёт всё время жизни потока

### 6. Разница между `malloc`, `operator new`, `new` и `new[]`
- `malloc` - `C-style`, выделяется сырой блок памяти, возвращается указатель на `void*`
- `operator new` - `C++-style`, выделяется сырой блок памяти, возвращается указатель на `void*`
- `new` - под капотом вызывает `operator new` и вызывает конструктор объекта по данному адресу
- `new[]` - выделяет память для массива объектов и вызывает конструктор для каждого объекта

### 7. `SIOF`: что это, как бороться
- `SIOF` - Static Initialization Order Fiasco
- В C++ порядок инициализации объектов со статическим временем жизни (глобальные переменные, static поля классов) гарантирован только внутри одной единицы трансляции (одного `.cpp` файла) — они создаются сверху вниз. Однако между разными файлами порядок не определен. Если объект `Logger` в `logger.cpp` должен инициализироваться раньше, чем `Database` в `db.cpp` (потому что конструктор `Database` хочет что-то записать в лог), вы попадаете в ситуацию «фиаско». В 50% случаев программа будет работать, а в остальных — упадет из-за обращения к неинициализированной памяти, так как линковщик может поставить `db.cpp` в очередь на инициализацию раньше, чем `logger.cpp`
- Способы борьбы:
    - `Construct on First Use`. Суть: превратить глобальный объект в локальную статическую переменную внутри функции:
      ```cpp
      // Вместо: Database db;
      Database& get_db() {
          static Database instance;  // Создастся ровно один раз при первом обращении
          return instance;
      }
      ```
    - `Constant Initialization`. Начиная с C++20, появилось ключевое слово `constinit`. Оно заставляет компилятор проверить, что переменная может быть инициализирована статически (на этапе компиляции или загрузки программы), а не динамически (вызовом конструктора в `runtime`).

---

## Билет №3: Категории значения (`rvalue` vs `lvalue`). `Temporarly lifetime extension`. Необходимость семантики перемещения. Жизнь до C++11. `rvalue references`. `std::move`.

### 1. Категории значений
- Каждое выражение в C++ характеризуется типом и категорией значения (`value category`)
- Всего есть три (на самом деле гораздо больше, порядка 7-8) различных категории значения:
    - `lvalue` (left hand side value)
    - `xvalue` (eXpiring value)
    - `prvalue` (pure rvalue)
- `xvalue` и `prvalue` похожи, для них определена категория `rvalue` (right hand side value)
- Интуиция: исторически назвали так, потому что `lvalue` может быть на левой стороне оператора присваивания, а `rvalue` - нет

Примеры:
```cpp
int i = 1;                          // i is lvalue, 1 is rvalue (literal constant)
int* y = &i;                        // we can take addresses from lvalue as they have location
1 = i;                              // ERROR: 1 is rvalue, can not be on the left
y = &42;                            // ERROR: 42 is rvalue, no location
const char(*ptr)[5] = &"abcd";      // string literal is lvalue (!)
std::cout << "Hello, " << name;     // std::ostream& operator<<(std::ostream&, const char*);

char arr[20];
arr[10] = 'z';                      // arr[10] returns lvalue reference

int a, b;
(a, b) = 5;                         // same as "b = 5;"

const char* p = ...;
*p++ = 'a';
```
- У `lvalue` можно брать адреса. У них есть конкретное местоположение в памяти.
- Важно отметить, что строковые литералы - это `lvalue`, у них можно взять адрес:
    - Небольшое пояснение: дело в том, что для строк выделяется место в бинарнике специально (ну Сквор так сказал), поэтому мы знаем их местоположение. А вот численные константы создаются, что называется, `in-place`
- На самом деле `lvalue` не всегда может быть слева, как подсказывает интуиция. Например, мы не можем ничего присвоить строке. Поэтому правильнее звучало бы определение о том, что у `lvalue` есть адрес

Ещё пачка примеров:
```cpp
int GetValue() {
    return 42;
}

int& GetGlobal() {
    static int j;
    return j;
}

GetValue() = 1;     // ERROR: GetValue is not lvalue, it is temporary returned from function
GetGlobal() = 5;    // ok, int& is lvalue reference, it has location
```

И ещё:
```cpp
// ok
int a = 42;
int& a_ref = a;  // a - lvalue
++a_ref;
a_ref = 5;

// not ok
int& b_ref = 10;  // 10 - константа
```

И ещё:
```cpp
void foo(int& x) {
}

foo(10);  // not ok
```
```cpp
void foo_const(const int& x) {
}

foo_const(10);  // ok
// по факту создаст новый объект, когда 10 передадут в функцию, и он уже будет иметь адрес в памяти
```

### 2. Temporary lifetime extension
Но продолжая пример выше: что же происходит на самом деле?

Продление времени жизни временного объекта:
```cpp
// Why?
// Well, it's a mistake and not at the same time.

// the following...
const int& ref = 10;

// ... would translate to:
int __internal_unique_name = 10;
const int& ref = __internal_unique_name;

// Without this rule we wouldn't do the things like:
class T;  // defined somewhere
T f();
void g(const T& x);

g(f());
const T& x = f();  // also works, то же самое, что и "T x = f()", так что лучше писать так, без выпендрёжа
```
Но вообще говоря не рекомендуется использовать эту фичу, ибо она довольно-таки неявная и неочевидная.

### 3. Move-семантика
До C++11:
```cpp
void move_string(std::string& s, std::string& f) {
    s.swap(f);
    f.clear();
}
```

Но в C++11 появились `rvalue references`. Это самая важная фича C++11. Выделяется она своими двумя амперсандами: `&&`. И нет, это не ссылка на ссылку, это просто синтаксис, чтобы различать `lvalue` и `rvalue` ссылки.

`rvalue`-ссылка - это контракт между вами и пользователем (вызывающей стороной) вашего класса (функции), который говорит, что вызывающая сторона вам явно передаёт объект, из которого вы можете забрать все внутренности себе. Он больше не нужен вызывающей стороне, единственное что сделает эта сторона - позовёт деструткор.

Вот, например, реализация копирования:
```cpp
Holder(Holder&& other) {
    data_ = other.data_;
    size_ = other.size_;
    other.data_ = nullptr;
    other.size_ = 0;
}
```

Оператор присваивания (перемещающий):
```cpp
Holder& operator=(Holder&& other) {
    if (this == &other) return *this;

    delete data_[];

    data_ = other.data_;
    size_ = other.size_;

    other.data_ = nullptr;
    other.size_ = 0;

    return *this;
}
```

Можно превращать `lvalue` ссылки в `rvalue` ссыслки через `std::move`:
```cpp
Holder h1(1000);
Holder h2(std::move(h1));
```
Это просто каст (`static_cast<Holder&&>`) к `rvalue` ссылке.

### 4. Немного об операторе присваивания-перемещения
Ещё раз упоминание о контракте между вызывающей стороной и вами:
- вызывающая сторона обязуется позвать деструктор
- вы обязуетесь оставить объект в консистентном состоянии для вызова деструктора

С появлением `move-семантики` правило трёх `rule-of-3` превратилось в правило пяти `rule-of-5`. Это означает, что если вы реализуете хотя бы один из конструкторов, или операторов присваивания, или деструктор, то вы обязаны реализовать и все остальные из перечисленных здесь специальных функций.

Вот, например, правильная реализация оператора присваивания-перемещающего:
```cpp
Holder& operator=(Holder&& other) {
    if (this == &other) {
        return *this;
    }

    delete[] ptr_;
    size_ = 0;

    // прикольная функция, которая пригождается при реализации
    // перемещащего оператора присваивания
    // присвает новое значение другому и зануляет указатель текущий
    ptr_ = std::exchange(other.ptr_, nullptr);
    // то есть ptr_ = other.ptr_
    // а other.ptr_ = nullptr

    std::swap(ptr_, other.ptr_);
    std::swap(size_, other.size_);

    return *this;
}
```

### 5. Немного о правиле 5
Хорошее правило: либо вы указываете все конструкторы/операторы (rule of 5), либо ничего (rule of 0):
1. Копирующий конструктор
2. Копирующий оператор присваивания
3. Перемещающий конструктор
4. Перемещающий оператор присваивания
5. Деструктор

Там, где можно, ставьте `= default` или `= delete`. Подавляющее большинство случаев.

Это реально маргинальный случай, когда в 2025 году требуется самому писать своё копирование. Пользуйтесь дефолтными определениями.

Всегда, когда вы пишите оператор присваивания перемещающий или конструктор перемещения, пишите ключевое слово `noexcept`:
```cpp
Holder(Holder&&) noexcept = default;
Holder& operator=(Holder&&) noexcept = default;
```
Например, если у вас вектор объектов вашего класса, то без `noexcept` он будет копировать ваши объекты, а не перемещать.


### 6. Чудеса реализации std::move
```cpp
template<typename T>
std::remove_reference_t<T>&& Move(T&& ref) {
    return static_cast<std::remove_reference_t<T>&&>(ref);
}
```
Мы хотим, чтобы функция работала и с временными объектами (rvalue), и с lvalue. Но как это сделать? Если коротко, то без `std::remove_reference_t<>` это работать не будет. В данной реализации `Move` получает не `rvalue`-ссылку, как может показаться, а универсальную ссылку. !!!Важно, что `rvalue` принимаемый, здесь шаблонный!!! Универсальная ссылка толька та, которая шаблонизирована. Работает же это примерно так:
- если передаём условно говоря T, то всё просто преобразуется в `rvalue`
- если передаём lvalue `T&`, то получается ситуация, когда передано `(T& && ref)`. Компилятор смотрит и видит `lvalue` и `rvalue`. `lvalue` по правилам языка сильнее, а потому остаётся именно `lvalue`, и всё работает корректно. 

Но ещё раз! Без `std::remove_reference_t<>` это не сработает!

### 7. Немного о константности
Никогда не делайте `move` на `const` объекты. `const` от типа может не отлипнуть:
```cpp
class Annotation {
public:
    explicit Annotation(const std::string text) : value_(std::move(text)) {
    }

    // we want to call string(string&&)
    // text is const
    // std::move(text) is const std::string&&
    // we called string(const std::string&)
    // it is a perf issue.

private:
    std::string value_;
};
```
Константная `rvalue`-ссылка самый бесполезный тип, который можно придумать. По факту по возможностям она вообще никак не отличается от константной `lvalue`-ссылки. В языке эта конструкция существует просто для симметрии.

### 8. Замечение об использовании `std::move`
Каждый раз, когда вы хотите передать `rvalue` ссылку дальше, нужно прописать `std::move`:
```cpp
class Annotation {
public:
    explicit Annotation(std::string&& text) : value_(text) {
    }

    // Здесь мы передаём lvalue, оно не отделимо от text
    // Поэтому происходит копирование
    // Если мы реально хотим работать с rvalue, то необходимо прописать std::move(text)

private:
    std::string value_;
};
```

---

## Билет №4: `std::forward`. Универсальные ссылки, `reference collapsing`. `Perfect forwarding`.

### 1. `reference collapsing`
Все доступные комбинации:
```cpp
void f1(std::string& s);
void f2(const std::string& s);
void f3(std::string&& s);
void f4(const std::string&& s);

std::string& s("Hi!");  // lvalue
const std::string& cs();  // const lvalue

f1(s);  // OK
f1(cs);  // ERROR
f1(std::move(s));  // ERROR
f1(std::move(cs));  // ERROR

f2(s);  // OK
f2(cs);  // OK
f2(std::move(s));  // OK
f2(std::move(cs));  // OK

f3(s);  // ERROR
f3(cs);  // ERROR
f3(std::move(s));  // OK
f3(std::move(cs));  // ERROR

f4(s);  // ERROR
f4(cs);  // ERROR
f4(std::move(s));  // OK
f4(std::move(cs));  // OK
```

### 2. Универсальные ссылки на примере реализации std::move
```cpp
template<typename T>
std:::remove_reference_t<T>&& Move(T&& ref) {
    return static_cast<std::remove_reference_t<T>&&>(ref);
}
```
Мы хотим, чтобы функция работала и с временными объектами (rvalue), и с lvalue. Но как это сделать? Если коротко, то без `std::remove_reference_t<>` это работать не будет. В данной реализации `Move` получает не `rvalue`-ссылку, как может показаться, а универсальную ссылку. !!!Важно, что `rvalue` принимаемый, здесь шаблонный!!! Универсальная ссылка толька та, которая шаблонизирована. Работает же это примерно так:
- если передаём условно говоря T, то всё просто преобразуется в `rvalue`
- если передаём lvalue `T&`, то получается ситуация, когда передано `(T& && ref)`. Компилятор смотрит и видит `lvalue` и `rvalue`. `lvalue` по правилам языка сильнее, а потому остаётся именно `lvalue`, и всё работает корректно. 

Но ещё раз! Без `std::remove_reference_t<>` это не сработает!

### 3. Perfect forwarding (всё ещё move-семантика)
`std::forward` нужен, чтобы просунуть принятое значение в следующую функцию. Пример:
```cpp
template<typename T, typename Arg>
void BenchVectorConstructor(Arg&& arg) {
    auto start = std::clock();
    std::vector<T> vec(std::forward<Arg>(arg));
    std::vector<T> vec(static_cast<Arg&&>(arg));
    auto end = std::clock();
}
```
Здесь мы принимаем универсальную ссылку, чтобы замерить время создания вектора. Но недостаточно просто написать `std::vector<T> vec(arg)`. Здесь будет копирование, мы померием вообще не то. Но в то же время нельзя написать и `std::vector<T> vec(std::move(arg))`, потому что, если пользователь дал нам `lvalue`, то мы просто украдём у него объект. Ну странная ситуация получается. Для этого и существует `std::forward`. Если нам передают `lvalue`, то он он работает с `lvalue`, если передают `rvalue`, то будет вызван `std::move`.

Но важно, в случае `std::forward` должна быть универсальная ссылка!

Ну а по сути `std::forward` нужен для перенаправления аргументов в базовый класс:
```cpp
template<typename U>
Status0r(U&& v) : Base(std::forward<U>(v)) {
}
```

### 4. Ref qualifiers (ну теперь точно последнее про move-семантику)
Мы уже писали перегрузки методов по константности:
```cpp
class Foo {
public:
    int& Get() {
        return value_;
    }

    const int& Get() const {
        return value_;
    }
};
```
Но можно ли перегружать не только по константности, но и по rvalue/lvalue?

Оказывается, что можно:
```cpp
struct Foo {
    int& Get() & { return value_; }

    const int& Get() const& { return value_; }

    int&& Get() && { return std::move(value_); }

    const int&& Get() const&& { return std::move(value_); }
    //  ^^^             ^^^
    // возвращаемый    принимаемый
    //    тип              тип
};
```

А как их звать?
```cpp
Foo{}.Get();  // call Get() &&

Foo foo;
foo.Get();  // call Get() &
std::as_const(foo).Get();  // call Get() const&
std::move(foo).get();  // call Get() &&
```


### 5. Deducing this
Выглядит не очень красиво, а потому в *C++23* появилась такая штука (похоже на Rust; имхо, я первое чё вспомнил, так это ООП в Python):
```cpp
SearchIndex Finish(this auto&& self) {  // this SearchIndex&& self, и он обязательно идёт первым
    if (std::exchange(finished_, true)) {
        throw std::runtime_error{"Double finish!"};
    }
    auto index = SearchIndex{std::move(self.inverted_index_)};
    self.~SearchIndexBuilde();  // вместо this->~SearchIndexBuilder()
    return index;
}

// Вместо того, чтобы писать SearchIndex Finish() && {}
```

До C++23 постоянно приходилось копипастить эти функции. Но с появлением `this auto&&`, можно шаблонизировать функцию, и тогда `this auto&&` будет восприниматься, как универсальная ссылка. Ну а тогда можно будет взависимости от типа кастомить функцию внутри одной реализации, избегая бесконечного копирования кода.

---

## Билет №5: Шаблоны. Виды шаблонных аргументов. `NTTP`. Вывод шаблонных аргументов в функциях и классах. `CTAD`.` Variadic templates` (лекция про паттерны).

### 1. Шаблоны и виды шаблонных аргументов
С шаблонами мы уже сталкивались: это параметризованная типами/значениями сущность (класс, функция, перемеренная):
```cpp
template<typename T1, typename T2>  // Между class и typename никакой разницы, но лучше typename
struct pair {
    T1 first;  // Use of T1
    T2 second;  // Use of T2
};

int x = 0;
pair<int, int> p(x, x);
pair<int, int&> p(x, x);  // Because why not

x = std::max<int32_t>(0, x);
```

Бывают шаблоны переменных: редко используемая фича, но иногда полезно:
```cpp
template<int A, int B>
constexpr int Sum = A + B;
```

### 2. NTTP (non-type template parametr)
Бывают значения в качестве шаблонных параметров:
```cpp
template<typename T, size_t Count>
class Array {
    T buf[Count];
};
```

Все аргументы шаблона подставляются на этапе компиляции! До этого момента на нас вряд ли наругаются. То есть, условно говоря, вот такой код будет валидным:
```cpp
template<typename T, size_t Count>
class Array {
    void Foo() {
        T value{42, 42, 42};
        value.unknown_method();
    }

    T buf[Count];
};
```
Хотя мы не знаем, есть ли у `T` конструктор для трёх значений, метод `unknown_method()`, тем не менее такой код будет корректным (до момента компиляции, конечно).

С C++20 сильно расширили возможные типы NTTP. С появлением стандарта нашлись любители, которые написали библиотеку регулярных выражений полностью на шаблонах:
```cpp
template<util::fixed_string regex>
class StaticRegularExpression;

StaticRegularExpression<"([0-9a-f]{8}-){3}([0-9a-f]{8}-)"> regex;

// util::fixed_string нужно реализовывать самим
```
Красиво, но безумно медленно компилируется, очень сложно дебажить, непонятно, зачем нужно, но красиво.

### 3. Вывод шаблонных аргументов в функциях и классах
Шаблонные аргументы и типы могут выводиться (в смысле вычисляться):
```cpp
template<typepname T>
T inc(T a) { return a + 1; }

// Компилятор автоматически понимает, что нужен int
inc(5);  // call inc<int>

int x = -1;
x = std::max(0, x);  // call std::max<int>();

template<int I>
int foo(std::integral_constant<int, I> _unused) {
    return I * I;
}

void bar() {
    foo(std::integral_constant<int, 5>{});  // call foo<5>
}

// Даже в таком сложном коде компилятор пониимает, что нужно подставить,
// а не заставляет пользователя явно прописывать тип при вызове foo()
```

Однако, иногда типы не вычисляются:
```cpp
uint32_t x = 0;
x = std::max(0, x);  // long compiler error
```

В том числе и для классов порой работает вычисление типов:
```cpp
std::vector v{1, 2, 3};  // it's OK
```

Или так:
```cpp
template<typename T, typename U>
class Pair {
public:
    Pair(T lhs, U rhs) : lhs_(std::move(lhs)), rhs_(std::move(rhs)) {
    }

private:
    T lhs_;
    U rhs_;
};

int main() {
    pair p{0, "Hello"};  // CE before C++17, pair<int, const char*> after C++17
}
```

Однако, в некоторых случаях в классах это работает не очень хорошо. Например:
```cpp
template<typename T, typename U>
class Pair {
public:
    Pair(const T& lhs, const U& rhs) : lhs_{lhs}, rhs_{rhs} {
    }

private:
    T lhs_;
    U rhs_;
};

int main() {
    pair p{0, "Hello"};  // U вычисляется, как char[6], однако, на этапе инициализации rhs мы получаем ошибку
}
```

### 4. CTAD (class templation deduction guide)
Но есть ужасная штука под названием `class template deduction guide`, она сильнее. Это способ направить компилятор на правильное вычисление типа:
```cpp
template<typename T1, typename T2>
struct pair {
    pair(const T1& f, const T2& s) : first(f), second(s) {
    }
    T1 first;
    T2 second;
};

template<typename T1, typename T2>
pair(const T1&, const T2&) -> pair<const T1&, const T2&>;

pair p{0, 1};  // pair<const int&, const int&>
```
Мы явно указываем, как из заданного конструктора вывести аргументы шаблона. Просто подсказываем, какие типы подставить. `Deduction Guide` пишется для конструкторов. Штука крайне полезная, ибо обычного вычисления типов не хватает зачастую. Тем более крайне полезна она при работе с ссылками.

### 5. `Variadic Templates`
Variadic Templates (шаблоны с переменным числом аргументов) — это механизм, появившийся в C++11, который позволяет шаблонам принимать произвольное количество аргументов любых типов.

**Объявление: Parameter Pack**

Ключевым элементом является многоточие (...), которое при использовании с именами типов называется пакетом параметров (parameter pack).
- `typename... Args` — пакет типов.
- `Args... args` — пакет значений.
```cpp
template <typename... Args> // Args — это пакет типов
void func(Args... args) {    // args — это пакет значений
    // ...
}
```

**Подсчет аргументов**

Чтобы узнать, сколько аргументов было передано в пакет, используется специальный оператор sizeof...:
```cpp
template <typename... Args>
void countArgs(Args... args) {
    size_t size = sizeof...(Args); // Возвращает количество элементов в пакете
}
```

**Распаковка пакета (Pack Expansion)**

Пакет нельзя использовать как массив (индексация args[0] не работает). Его нужно «распаковать».
1) Рекурсивный метод (Классика до C++17)
Мы отделяем первый аргумент от остальных, обрабатываем его, а остальные передаем в рекурсивный вызов.
```cpp
void print() {} // Базовая функция для завершения рекурсии

template <typename First, typename... Rest>
void print(First first, Rest... rest) {
    std::cout << first << " ";
    print(rest...); // Распаковка: превращается в print(arg1, arg2, ...)
}
```
2) Выражения свертки (Fold Expressions, C++17) — Рекомендуется в 2025 году
Это способ применить бинарный оператор ко всем элементам пакета без рекурсии.
```cpp
template <typename... Args>
auto sum(Args... args) {
    return (args + ...); // Правая свертка: (a + (b + (c + d)))
}

template <typename... Args>
void printAll(Args... args) {
    (std::cout << ... << args) << "\n"; // Свертка через оператор <<
}
```

---

## Билет №6: Обработка ошибок: исключения, типы-суммы или произведения. Плюсы и минусы разных подходов к обработке ошибок. `noexcept`, исключения из деструкторов, `RAII`.

### 1. Подходы к обработке ошибок, плюсы и минусы каждого из подходов
#### Исключения (`Exceptions`)
Используются для «исключительных» ситуаций (нехватка памяти, обрыв сети). Пример:
```cpp
double divide(double a, double b) {
    if (std::abs(b) < 1e-9) 
        throw std::invalid_argument("Division by zero");  // Бросаем объект исключения
    return a / b;
}

try {
    double res = divide(10, 0);
} catch (const std::exception& e) {
    std::cerr << e.what();  // Обработка
}
```
**Плюс**: Код логики (res = a / b) отделен от кода обработки ошибок.
**Минус**: Сложно отследить путь исполнения (неявные переходы).

#### Типы-суммы (std::expected — C++23)
Это современный стандарт. Функция возвращает либо значение, либо ошибку. Пример:
```cpp
#include <expected>

std::expected<double, std::string> safe_divide(double a, double b) {
    if (std::abs(b) < 1e-9)
        return std::unexpected("Division by zero");  // Возвращаем ошибку как значение
    return a / b;
}

auto res = safe_divide(10, 0);
if (res) {
    std::cout << *res;  // Работаем со значением
} else {
    std::cout << res.error();  // Работаем с ошибкой
}
```
**Плюс**: Ошибка видна в интерфейсе функции, нет накладных расходов на развертку стека.

### 2. Спецификатор `noexcept`
Он говорит компилятору: «эта функция гарантированно не выкинет исключение». Пример:
```cpp
void fast_func() noexcept {
    // Если здесь случится throw, программа вызовет std::terminate()
}
```

Зачем это нужно для `std::vector`: При расширении `std::vector` перевыделяет память. Если ваш конструктор перемещения помечен `noexcept`, вектор использует перемещение (быстро). Если не помечен — вектор будет копировать объекты (медленно), потому что боится, что при перемещении случится исключение и данные будут потеряны.

### 3. Исключения из деструкторов
В C++ деструкторы по умолчанию имеют `noexcept`(true).

Почему нельзя бросать исключения:
- Представьте ситуацию «развертки стека» (`stack unwinding`): вылетело исключение, и система начинает удалять локальные объекты. Если в процессе удаления объекта его деструктор бросит второе исключение — среда выполнения не поймет, какое из них обрабатывать, и мгновенно «уронит» программу через `std::terminate`.
- Пример «плохого» кода:
  ```cpp
  struct Bad {
      ~Bad() { throw std::runtime_error("Double trouble"); } 
  };

  void test() {
      Bad b;  // Деструктор вызовется здесь. Если это часть catch-блока — краш.
  }
  ```

### 4. RAII (Resource Acquisition Is Initialization)
Это главная концепция безопасности в C++. Ресурс должен принадлежать объекту, который управляет его временем жизни. Пример (самописный RAII для файла):
```cpp
class FileWrapper {
    FILE* f;
public:
    FileWrapper(const char* name) {
        f = fopen(name, "r");
        if (!f) throw std::runtime_error("File error");
    }
    ~FileWrapper() {
        if (f) fclose(f);  // Ресурс освободится ВСЕГДА, даже при исключении
    }
};

void process() {
    FileWrapper fw("data.txt");
    do_something();  // Если здесь вылетит исключение, деструктор FileWrapper всё равно закроет файл.
}
```

---

## Билет №7: Порядок сборки программ компилятором. Инкрементальность компиляции. `One definition rule`. Исключения из `ODR`. Смысл ключевого слова `inline`. Правила при написании кода для защиты от нарушения `ODR`.

### 1. Порядок сборки программы
Процесс превращения .cpp в исполняемый файл состоит из четырех этапов:
1. Препроцессинг (`cpp`):
    - Обработка директив `#include` (копирование содержимого файлов), `#define` (подстановка текста), `#ifdef` и др.
    - Результат: Единица трансляции (`Translation Unit`) — гигантский текстовый временный файл.
2. Компиляция (`ccl`):
    - Анализ синтаксиса и генерация ассемблерного кода для конкретной архитектуры.
3. Ассемблирование (`as`):
    - Превращение ассемблерного кода в объектный файл (машинный код).
    - Результат: Объектный файл (`.obj` или `.o`). Содержит код, данные и таблицу символов (список имен функций и переменных).
4. Линковка (Компоновка, `ld`):
    - Сборка всех объектных файлов и библиотек в один бинарный файл. Линковщик сопоставляет вызовы функций с их определениями.

### 2. Инкрементальность компиляции
Компиляция в C++ по умолчанию инкрементальна на уровне файлов.
- Если вы изменили один `.cpp` файл, компилятору нужно пересобрать только его в объектный файл, а затем запустить линковщик. Остальные `.cpp` файлы пересобирать не нужно.
- Проблема: Если вы изменили один `.h` файл, который подключен в 100 файлах `.cpp`, все эти 100 файлов придется перекомпилировать.

### 3. One Definition Rule (`ODR`)
`ODR` — это правило, гарантирующее однозначность программы. Оно состоит из трех уровней:
1. В любой единице трансляции не может быть более одного определения сущности (переменной, функции, класса).
2. Во всей программе (во всех `.obj`) должно быть ровно одно определение функции или переменной с внешней линковкой.
3. Классы и инлайновые сущности могут быть определены в разных единицах трансляции, но эти определения должны быть идентичны (текстуально и по смыслу).

### 4. Исключения из `ODR`
Некоторые сущности можно определять в нескольких единицах трансляции (обычно через заголовочные файлы):
- Классы (`struct`, `class`).
- Перечисления (`enum`).
- Инлайновые (`inline`) функции и переменные.
- Шаблоны (`templates`).

Пример: Если вы определите `struct Point { int x, y; };` в `point.h`, и подключите его в два файла `.cpp`, ошибки не будет, так как класс — это исключение. Но если определения будут разными (в одном файле `int x`, в другом `double x`), это приведет к `Undefined Behavior`.

### 5. Смысл ключевого слова `inline`
В современном C++ (2025 год) `inline` — это не команда компилятору «встрой код функции в место вызова», а указание линковщику:
- Основной смысл: Разрешить определению функции (или переменной с C++17) присутствовать в нескольких объектных файлах.
- Как работает: Линковщик видит несколько одинаковых определений `inline` функции и просто выбирает одно из них, выбрасывая остальные.

Пример:
```cpp
// В заголовочном файле
inline int sum(int a, int b) { return a + b; }
```
Без `inline` линковщик выдаст ошибку `multiple definition of 'sum'`.

### 6. Правила защиты от нарушения `ODR`
Чтобы не «сломать» линковку, следуйте этим правилам:
1. `Header Guards`: Всегда используйте #ifndef или #pragma once в заголовках. Это защищает от повторного включения в рамках одной единицы трансляции.
2. Разделение на объявление и определение:
    - В `.h` файлах — только объявления (`extern int x;`, `void func();`).
    - В `.cpp` файлах — определения (`int x = 5;`, `void func() { ... }`).
3. Использование `inline` для кода в заголовках: Если вы пишете тело функции прямо в `.h` файле, она обязана быть либо `inline`, либо `static`, либо методом внутри класса.
4. Анонимные пространства имен: Для локальных функций внутри `.cpp` используйте namespace `{ ... }`, чтобы скрыть их от линковщика и избежать конфликтов с другими файлами.

Пример нарушения `ODR`

Файл `a.h`:
```cpp
int x = 10; // ОШИБКА: определение переменной в заголовке без inline
```

Если `a.h` подключат два файла `main.cpp` и `other.cpp`, линковщик увидит две переменные `x` и упадет с ошибкой.

Исправление:
```cpp
// Вариант 1 (C++17+)
inline int x = 10; 

// Вариант 2 (Классический)
extern int x; // в .h
int x = 10;    // в .cpp
```

---

## Билет №8: Метапрограмирование. Частичные специализации, `SFINAE`. `if constexpr`. Концепты.

Метапрограммирование — это техника написания программ, которые порождают или манипулируют другими программами (или своими частями) во время компиляции. В C++ это позволяет выполнять вычисления, принимать решения и генерировать код на этапе компиляции, что ведет к более эффективному и гибкому runtime-коду.

Ключевые инструменты в C++: шаблоны, макросы, `constexpr`-выражения, `SFINAE`, `if constexpr`, концепты (C++20).

### 1. Частичные специализации шаблонов (Partial Template Specialization)
- Определение: Это механизм, позволяющий предоставить альтернативную реализацию шаблона класса (но не функции!) для определенного подмножества его возможных аргументов, сохраняя при этом некоторые параметры шаблона свободными.
- Цель: Изменять поведение или структуру класса в зависимости от свойств типов.
- Пример: std::unique_ptr для массивов.
```cpp
// Основной шаблон
template <typename T>
class MyVector {
    // Базовая реализация для произвольного типа T
};

// Частичная специализация для указателей
template <typename T>
class MyVector<T*> {
    // Специальная оптимизированная реализация для указателей
    // Например, можно хранить дополнительную информацию о владении
};

// Полная специализация для void*
template <>
class MyVector<void*> {
    // Еще более специализированная реализация
};
```
Важно: Работает только для классов. Для функций используется перегрузка или другие техники (SFINAE, концепты).

Позволяет создавать мощные, оптимизированные контейнеры и утилиты (например, `std::vector<bool>` — это специализация).

### 2. SFINAE (Substitution Failure Is Not An Error)
- Определение: Это правило в процессе разрешения перегрузки шаблонных функций. Если при подстановке конкретных типов в шаблон аргументы функции становятся некорректными (например, возникает недопустимый тип), это не вызывает ошибку компиляции. Вместо этого такая перегрузка просто исключается из множества кандидатов.
- Цель: Условно включать или исключать перегрузки функций и специализации шаблонов на этапе компиляции, создавая "шаблонные ограничения" до появления концептов.
- Механизм: Реализуется с помощью вспомогательных шаблонов, чаще всего std::enable_if.

Как работает `std::enable_if`:
```cpp
template <bool Cond, typename T = void>
struct enable_if {};

template <typename T> // Специализация для true
struct enable_if<true, T> {
    using type = T;
};

template <bool Cond, typename T = void>
using enable_if_t = typename enable_if<Cond, T>::type;
```
Если `Cond` — `false`, у `enable_if<false, T>` нет члена `type`, что вызывает ошибку подстановки (SFINAE).

Пример проблемы:
```cpp
template<class T>
class Array {
public:
    Array(size_t n, const T& value = T{}); // (1)
    template<typename Iterator>
    Array(Iterator begin, Iterator end);   // (2)
};
Array<int> ar(5, 3); // Вызывает (2)! Ожидалось (1).
```
Для `ar(5, 3): Iterator` выводится как `int`. Конструктор (2) предпочтительнее, так как не требует преобразования `int -> size_t`.

Решение с SFINAE:
```cpp
template<typename Iterator,
         typename = std::enable_if_t<!std::is_integral_v<Iterator>>>
Array(Iterator begin, Iterator end);
```
Для `Iterator = int: !std::is_integral_v<int>` — `false`. `enable_if_t<false>` — некорректный тип. Эта перегрузка исключается по SFINAE, остается только (1).

Типичные места размещения `enable_if`:
- Дополнительный аргумент по умолчанию: template<typename T, typename = enable_if_t<...>>.
- Возвращаемый тип: enable_if_t<..., ReturnType> foo().
- Аргумент функции: void foo(enable_if_t<...>* = nullptr).

Особенность для методов шаблонных классов:
```cpp
template<typename T>
class UniquePtr {
public:
    // Ошибка! T уже известен, подстановка не происходит в нужный момент.
    template<typename = std::enable_if_t<!std::is_same_v<T, void>>>
    T& Unref(); // CE

    // Правильно: вводим новый параметр шаблона U, зависящий от T.
    template<typename U = T,
             typename = std::enable_if_t<!std::is_same_v<U, void>>>
    U& Unref(); // OK
};
```
Недостатки SFINAE: Синтаксис громоздкий, ошибки компиляции сложны для понимания, код становится менее читаемым.

### 3. `if constexpr` (начиная с C++17)
- Определение: Это инструкция условной компиляции внутри шаблонных функций или constexpr-функций. Условие вычисляется на этапе компиляции. В зависимости от его истинности, компилируется только одна ветка (then или else), а другая полностью отбрасывается.
- Цель: Упростить метапрограммирование, избавившись от необходимости множественных специализаций или хитростей с SFINAE для условной компиляции внутри одной функции.

Пример:
```cpp
// Старый способ с SFINAE и перегрузками
template <typename T>
auto get_value(const T& t) -> decltype(t.first) { return t.first; }
template <typename T>
auto get_value(const T& t) -> decltype(t.second) { return t.second; }

// Новый способ с if constexpr
template <typename T>
auto get_value(const T& t) {
    if constexpr (has_first_member_v<T>) {
        return t.first;
    } else if constexpr (has_second_member_v<T>) {
        return t.second;
    } else {
        return t;
    }
}
```
Ключевые особенности:
- Не-шаблонный код внутри отброшенной ветки не проверяется на корректность. Это позволяет писать код, который имеет смысл только для определенных типов.
- Позволяет писать более "естественный" императивный код для метапрограммирования.
- Часто используется вместе с `std::is_same_v`, `std::is_integral_v` и другими трейтами.

Связь с SFINAE: `if constexpr` во многих случаях заменяет простые случаи использования SFINAE, делая код чище. Однако для условного включения/исключения целых перегрузок функций SFINAE (или концепты) все еще необходимы.

### 4. Концепты (Concepts, начиная с C++20)
- Определение: Это механизм, позволяющий на уровне языка формулировать требования к шаблонным параметрам. Концепт — это именованный набор ограничений (предикатов времени компиляции), которые должны выполняться для аргумента шаблона.
- Цель: Прийти на смену SFINAE, сделав код с шаблонами:
- Читаемым: Требования явно указаны в синтаксисе.
- Удобным в отладке: Компилятор выдает понятные сообщения об ошибках, указывая, какое именно требование не выполнено.
- Мощным: Ограничения можно комбинировать (&&, ||).

Синтаксис:
```cpp
// Объявление концепта
template <typename T>
concept HasSize = requires(const T& t) {
    t.size(); // Проверяет наличие метода .size()
};

// Использование в качестве типа ограничения
template <HasSize Container>
void print_size(const Container& c) {
    std::cout << c.size() << '\n';
}
// Или в более общей форме:
template <typename Container>
    requires HasSize<Container>
void print_size(const Container& c) { /*...*/ }
// Или в сокращенном виде синтаксиса шаблона:
void print_size(const HasSize auto& c) { /*...*/ }
```
Требования (`requires`):
- Простые: `t.size()` — проверка, что выражение корректно.
- Составные: `{ t.size() } -> std::convertible_to<size_t>;` — проверка типа выражения.
- Вложенные: `requires { typename T::value_type; }` — проверка наличия вложенного типа.
- Составные концепты: `template<typename T> concept Sortable = HasSize<T> && HasLess<T>;`

Пример решения проблемы с конструктором `Array` (замена SFINAE):
```cpp
template<class T>
class Array {
public:
    Array(size_t n, const T& value = T{});
    template<std::forward_iterator Iterator> // Используем стандартный концепт
    Array(Iterator begin, Iterator end);
};
// Или со своим ограничением:
template<typename Iterator>
    requires (!std::is_integral_v<Iterator>)
Array(Iterator begin, Iterator end);
```

Преимущества над SFINAE:
- Ясность: Код выражает намерение, а не хитроумный трюк.
- Лучшие ошибки: Компилятор четко указывает, какой концепт не удовлетворен.
- Перегрузка: Функции могут быть перегружены по концептам, что более интуитивно, чем перегрузка по SFINAE.
- Связь с `if constexpr`: Концепты часто используются внутри `if constexpr` для условной компиляции кода в зависимости от свойств типа.

---

## Билет №9: Многопоточность. Введение: потоки, разделяемая память, `race condition`, `mutex`

Многопоточность — это модель выполнения, позволяющая программе иметь несколько потоков управления, работающих параллельно. В C++ стандартная поддержка многопоточности появилась в C++11, предоставив кроссплатформенные средства для работы с потоками и синхронизацией.

### 1. Потоки (`std::thread`, `std::jthread`)
Поток — это наименьшая единица исполнения, которую может планировать операционная система. Потоки одного процесса разделяют общее адресное пространство (память), что позволяет им легко обмениваться данными, но также создает проблемы синхронизации.

Создание и запуск потока в C++:
```cpp
#include <iostream>
#include <thread>

void print_message(const std::string& msg) {
    std::cout << msg << std::endl;
}

int main() {
    // Создание потока с функцией и аргументами
    std::thread t1(print_message, "Hello from thread!");
    
    // Создание потока с лямбда-выражением
    std::thread t2([]() {
        std::cout << "Hello from lambda thread!" << std::endl;
    });
    
    // Ожидание завершения потоков
    t1.join();
    t2.join();
    
    return 0;
}
```

Управление жизненным циклом потока:
- `join()` — блокирует вызывающий поток до тех пор, пока целевой поток не завершит выполнение. Обязателен для вызова, если поток не был `detached`. После вызова `join()` поток становится не `joinable`.
- `detach()` — разрешает потоку работать независимо (в режиме "фонового" выполнения). После `detach()` поток больше не может быть `joinable`. Не рекомендуется к использованию, так как сложно контролировать время жизни таких потоков.

`joinable()` — проверяет, можно ли вызвать `join()` для потока (поток был создан и еще не был `join`/`detach`).

`std::jthread` (C++20):
Улучшенная версия `std::thread`, которая в деструкторе автоматически вызывает `join()`, если поток еще `joinable`. Предотвращает случайные утечки ресурсов.
```cpp
#include <thread>

int main() {
    std::jthread t1([]() {
        // Работа потока
    });
    // Деструктор t1 автоматически вызовет join()
    return 0;
}
```
Ключевой момент: Потоки, созданные с помощью `std::thread`, должны быть либо `join`, либо `detach` перед уничтожением объекта `std::thread`. Иначе программа завершится с вызовом `std::terminate()`.

### 2. Разделяемая память (`Shared Memory`)
Разделяемая память — это модель, при которой потоки одного процесса имеют общее адресное пространство и могут напрямую обращаться к одним и тем же данным.

Преимущества:
- Высокая скорость обмена данными (нет необходимости в копировании или системных вызовах).
- Естественность для программиста (работа с обычными переменными).

Проблемы:
- Гонки данных (Data Races) — когда несколько потоков одновременно обращаются к одной и той же памяти, и хотя бы один из них модифицирует данные.
- Сложность синхронизации — необходимо явно координировать доступ к общим данным.

Пример разделяемой памяти:
```cpp
#include <thread>

int shared_counter = 0;  // Разделяемая переменная

void increment() {
    for (int i = 0; i < 1000000; ++i) {
        shared_counter++;  // Небезопасный доступ из нескольких потоков
    }
}

int main() {
    std::thread t1(increment);
    std::thread t2(increment);
    
    t1.join();
    t2.join();
    
    // shared_counter, скорее всего, будет меньше 2000000
    std::cout << "Counter: " << shared_counter << std::endl;
    return 0;
}
```

### 3. Состояние гонки (`Race Condition`) и Гонка данных (`Data Race`)
#### `Race Condition` (Состояние гонки)
- Определение: Ситуация, когда поведение программы зависит от относительного порядка выполнения операций в различных потоках, при этом этот порядок не определен.
- Характеристики:
    - Не является неопределенным поведением (UB) в общем случае.
    - Проявляется в логических ошибках, когда результат вычислений зависит от непредсказуемого чередования потоков.
- Пример: Два потока выводят `"Hello, "` и `"threads!"` в произвольном порядке. Нет гарантии, что `"Hello, "` будет выведено раньше.

#### `Data Race` (Гонка данных)
- Определение: Частный (и наиболее опасный) случай `race condition`, когда два или более потока обращаются к одной и той же ячейке памяти одновременно, и хотя бы один из доступов является записью, причем эти доступы не упорядочены с помощью механизмов синхронизации.
- Характеристики:
    - Является неопределенным поведением (UB) согласно стандарту C++.
    - Приводит к непредсказуемым результатам, повреждению данных, крахам программ.
- Пример: Несколько потоков одновременно выполняют `sum++`. Операция `sum++` не атомарна (чтение-модификация-запись), что приводит к потере обновлений.

Различие:
- `Race Condition` — более широкое понятие, включает логические ошибки из-за неопределенного порядка.
- `Data Race` — конкретный вид `race condition` с одновременным доступом к памяти на запись, являющийся UB.

Пример Data Race:
```cpp
int x = 0;

void writer() {
    x = 42;  // Поток 1: запись
}

void reader() {
    std::cout << x;  // Поток 2: чтение
}
// Если выполнение не синхронизировано - это data race (UB)
```

### 4. Мьютекс (`std::mutex`)
Мьютекс (`mutual exclusion`, взаимное исключение) — примитив синхронизации, который обеспечивает, чтобы только один поток в данный момент времени мог выполнять определенный участок кода (критическую секцию).

Принцип работы:
- Поток вызывает lock() для захвата мьютекса.
- Если мьютекс свободен, поток захватывает его и продолжает выполнение.
- Если мьютекс уже захвачен другим потоком, текущий поток блокируется до освобождения мьютекса.
- После завершения работы с разделяемыми данными поток вызывает unlock() для освобождения мьютекса.

Пример использования:
```cpp
#include <iostream>
#include <thread>
#include <mutex>

int64_t sum = 0;
std::mutex mtx;  // Мьютекс для защиты доступа к sum

void increment() {
    for (int i = 0; i < 1000000; ++i) {
        mtx.lock();    // Захватываем мьютекс
        sum++;         // Критическая секция - безопасный доступ
        mtx.unlock();  // Освобождаем мьютекс
    }
}

int main() {
    std::thread t1(increment);
    std::thread t2(increment);
    
    t1.join();
    t2.join();
    
    // Теперь sum гарантированно равно 2000000
    std::cout << "Sum: " << sum << std::endl;
    return 0;
}
```

Проблемы прямого использования `lock()`/`unlock()`:
- Если между `lock()` и `unlock()` выбросится исключение, мьютекс останется захваченным навсегда (утечка мьютекса).
- Легко забыть вызвать unlock().
- Нельзя копировать мьютекс.

Решение: `std::lock_guard` и `std::unique_lock`. `RAII`-обертки, которые автоматически захватывают мьютекс в конструкторе и освобождают в деструкторе.
```cpp
void safe_increment() {
    for (int i = 0; i < 1000000; ++i) {
        std::lock_guard<std::mutex> lock(mtx);  // Конструктор вызывает mtx.lock()
        sum++;  // Критическая секция
        // Деструктор lock_guard автоматически вызовет mtx.unlock()
    }
}
```

#### Производительность и кэш-линии:
Производительность: Частое использование мьютексов может свести на нет выгоду от многопоточности из-за накладных расходов на блокировки и ожидания.

Кэш-линии: Когда один поток захватывает мьютекс, процессор должен обеспечить согласованность кэшей всех ядер, что может быть дорогой операцией (эффект "ложного разделения кэша", false sharing).

Профилирование: Для анализа производительности многопоточных программ необходимы специальные инструменты (perf, VTune, Яндекс Perforator), которые показывают, где тратится время, сколько потоков заблокировано и т.д.

### 5. Практические рекомендации
- Избегайте разделяемого состояния — лучший способ избежать проблем синхронизации.
- Используйте мьютексы для защиты всех разделяемых данных, которые изменяются.
- Всегда используйте `RAII`-обертки (`lock_guard`, `unique_lock`) вместо прямого вызова `lock()`/`unlock()`.
- Держите критические секции как можно короче — выполняйте в них только минимально необходимые операции.
- Для счетчиков и простых атомарных операций рассмотрите использование `std::atomic`.
- Проектируйте программу так, чтобы потоки были максимально независимы.

---

## Билет №10: `Condition variables`. Решаемая задач, интерфейс, `spurious wakeups`, порядок корректного взаимодействия через `conditino variable`.

`Condition variable` (условная переменная) — это механизм синхронизации, позволяющий потокам ожидать наступления определенного условия, связанного с разделяемыми данными. Это более высокоуровневый примитив, чем мьютекс, который решает проблему активного ожидания (busy-waiting).

### 1. Решаемая задача
Основная проблема, которую решают `condition variables`: Эффективная синхронизация потоков, когда один или несколько потоков должны ожидать, пока не будет выполнено определенное условие над разделяемыми данными.

Конкретные сценарии:
- Ожидание ресурса: Поток ждет, когда в пуле появится свободный ресурс (семафор, пул соединений).
- Producer-Consumer: Поток-потребитель ждет, когда поток-производитель добавит данные в буфер.
- Ожидание завершения задачи: Потоки ждут, когда главный поток инициализирует систему.
- Барьеры: Все потоки ждут, пока другие достигнут определенной точки.

Альтернатива без `condition variable` — активное ожидание (`busy-waiting`):
```cpp
// ПЛОХО: активное ожидание (busy-waiting)
void wait_for_condition() {
    while (!condition) {
        std::this_thread::sleep_for(std::chrono::milliseconds(10));
    }
    // Выполнить работу
}
```

Недостатки активного ожидания:
- Трата процессорного времени на постоянные проверки
- Задержки реакции (если `sleep` слишком долгий)
- Лишняя нагрузка на систему синхронизации (постоянные `lock`/`unlock`)

### 2. Интерфейс `std::condition_variable`
Основные методы:
- `wait(lock, predicate)` — ожидание условия
  ```cpp
  template<typename Predicate>
  void wait(std::unique_lock<std::mutex>& lock, Predicate pred);
  ```
    - Работа:
        - Атомарно разблокирует lock и приостанавливает выполнение потока.
        - Когда поток будет разбужен (через notify_one() или notify_all()), он снова захватывает lock.
        - Проверяет предикат pred():
        - Если pred() возвращает true — продолжает выполнение.
        - Если pred() возвращает false — снова переходит в состояние ожидания.
    
        Важно: Поток всегда должен проверять условие в цикле, даже после пробуждения (из-за spurious wakeups).
- `notify_one()` — пробуждение одного потока. Пробуждает один случайный поток из ожидающих на данной condition variable.
- `notify_all()` — пробуждение всех потоков. Пробуждает все потоки, ожидающие на данной condition variable.
    - Пример из лекции — семафор:
      ```cpp
      class Semaphore {
          int counter_ = 0;
          std::mutex mtx_;
          std::condition_variable not_empty_; // Condition variable

      public:
          void Enter() {
              std::unique_lock lock{mtx_};
              // Ожидаем, пока не появится токен
              not_empty_.wait(lock, [this] { return counter_ > 0; });
              counter_--;
          }

          void Leave() {
              std::lock_guard guard{mtx_};
              counter_++;
              not_empty_.notify_one(); // Пробуждаем один ожидающий поток
          }
      };
      ```

### 3. `Spurious Wakeups` (Ложные пробуждения)
- Определение: Ситуация, когда поток, ожидающий на `condition variable`, может быть разбужен без явного вызова `notify_one()` или `notify_all()`.
- Причины:
    - Особенности реализации ОС: Некоторые планировщики потоков могут будить потоки по другим причинам.
    - Аппаратные прерывания.
    - Оптимизации в реализации `condition variable`.
- Важное следствие: Поток не может полагаться только на факт пробуждения как на индикатор того, что условие выполнено. Условие всегда должно проверяться явно.

Неправильно (без проверки условия):
```cpp
// ОПАСНО: возможна гонка данных или неправильное поведение
std::unique_lock lock{mtx};
cv.wait(lock); // Ждем без предиката
// Думаем, что условие выполнено, но это может быть ложное пробуждение
process_data();
```

Правильно (с проверкой условия):
```cpp
// БЕЗОПАСНО: всегда проверяем условие
std::unique_lock lock{mtx};
cv.wait(lock, [] { return condition_is_true(); });
// Гарантированно: condition_is_true() == true
process_data();
```

Эквивалентная запись (явный цикл):
```cpp
// То же самое, что и wait с предикатом
std::unique_lock lock{mtx};
while (!condition_is_true()) {
    cv.wait(lock);
}
process_data();
```

### 4. Порядок корректного взаимодействия через `condition variable`
Общий паттерн использования:
- Захват мьютекса (`lock_guard` или `unique_lock`)
- Проверка/модификация разделяемых данных под мьютексом
- Ожидание условия (если оно не выполнено) или оповещение (если изменили данные)
- Освобождение мьютекса (автоматически в деструкторе)

Для потока-ожидающего (`consumer/waiting thread`):
```cpp
// 1. Захватываем мьютекс (unique_lock, так как он умеет разблокироваться)
std::unique_lock<std::mutex> lock(mutex);

// 2. Проверяем условие В ЦИКЛЕ (защита от spurious wakeups)
while (!condition(data)) {
    // 3. Атомарно: разблокируем мьютекс и переходим в режим ожидания
    cv.wait(lock);
    // 4. После пробуждения: автоматически захватываем мьютекс снова
    // 5. Снова проверяем условие (возвращаемся к шагу 2)
}

// 6. Условие выполнено: работаем с данными под защитой мьютекса
process_data(data);

// 7. Мьютекс автоматически освобождается при выходе из scope
```

Для потока-оповещающего (`producer/signaling thread`):
```cpp
// 1. Захватываем мьютекс
{
    std::lock_guard<std::mutex> lock(mutex);
    
    // 2. Модифицируем разделяемые данные
    update_data(data);
    
    // 3. Устанавливаем условие, которое ждут другие потоки
    // (это может быть просто изменение переменной)
    
    // 4. Оповещаем ждущие потоки
    // cv.notify_one(); // Если нужно разбудить только один поток
    cv.notify_all();    // Если нужно разбудить все ожидающие потоки
}
// 5. Мьютекс автоматически освобождается
```

### 5. Важные правила:
1. Всегда защищайте разделяемые данные мьютексом:
```cpp
// ПРАВИЛЬНО
std::unique_lock lock(mutex);
cv.wait(lock, [] { return ready; });

// НЕПРАВИЛЬНО - data race!
cv.wait(lock);  // А кто проверяет ready?
if (ready) {    // ready могло измениться после wait!
    // ...
}
```
2. Мьютекс должен быть одним и тем же для `wait` и модификации данных:
```cpp
std::mutex mutex;
std::condition_variable cv;
bool ready = false;

// Поток A (ожидающий)
std::unique_lock lock(mutex);  // Захватываем mutex
cv.wait(lock, [] { return ready; });

// Поток B (оповещающий)
{
    std::lock_guard lock(mutex);  // Захватываем ТОТ ЖЕ mutex
    ready = true;                 // Модифицируем данные
    cv.notify_one();              // Оповещаем
}
```
3. Предпочитайте `notify_one()` когда возможно:
    - `notify_one()` — эффективнее, будит только один нужный поток.
    - `notify_all()` — нужен, когда условие удовлетворяет всем ожидающим потокам (например, "запуск всех потоков после инициализации").
4. Избегайте `lost wakeup` (потерянного пробуждения):
```cpp
// ОПАСНО: возможен lost wakeup
if (!condition) {
    // Между проверкой condition и wait, другой поток может
    // установить condition и вызвать notify_one()
    cv.wait(lock);  // И тогда мы заснем навсегда
}

// БЕЗОПАСНО: атомарная проверка и ожидание
cv.wait(lock, [] { return condition; });
Пример: Producer-Consumer с bounded buffer
cpp
template<typename T>
class BoundedBuffer {
    std::queue<T> buffer_;
    size_t capacity_;
    std::mutex mtx_;
    std::condition_variable not_empty_;  // Для consumer
    std::condition_variable not_full_;   // Для producer
    
public:
    void push(T item) {
        std::unique_lock lock(mtx_);
        // Ждем, пока не освободится место
        not_full_.wait(lock, [this] { return buffer_.size() < capacity_; });
        
        buffer_.push(std::move(item));
        
        // Оповещаем consumer, что появился элемент
        not_empty_.notify_one();
    }
    
    T pop() {
        std::unique_lock lock(mtx_);
        // Ждем, пока не появится элемент
        not_empty_.wait(lock, [this] { return !buffer_.empty(); });
        
        T item = std::move(buffer_.front());
        buffer_.pop();
        
        // Оповещаем producer, что освободилось место
        not_full_.notify_one();
        
        return item;
    }
};
```

---

## Билет №11: Понятие `thread pool`. Структура `thread pool`. Выбор оптимального количества потоков для конкретного приложения.

`Thread pool` (пул потоков) — это архитектурный паттерн многопоточного программирования, при котором фиксированное количество потоков создается заранее и используется для выполнения асинхронных задач. Это фундаментальный строительный блок современных многопоточных приложений.

### 1. Понятие `Thread Pool` и его необходимость
Проблемы наивного подхода (создание потока на каждую задачу):
- Высокая стоимость создания потоков:
    - Создание потока — дорогая операция (~5 микросекунд на Linux).
    - Требуется выделение стека, инициализация структур данных в ядре, настройка контекста.
- Высокая стоимость переключения контекста:
    - Переключение между потоками выполняется ядром ОС и стоит 3-100 микросекунд.
    - При большом количестве потоков планировщик ОС тратит значительное время на управление ими.
- Ограничения масштабирования:
    - Планировщик ОС (например, CFS в Linux) должен управлять всеми потоками.
    - На больших серверах практический предел — 1000-2000 потоков.
- Непредсказуемое поведение:
    - Если каждая часть программы создает свои потоки, невозможно контролировать общее количество потоков в системе.
    - Может возникнуть ситуация, когда сотни потоков конкурируют за процессорное время.

Решение — `Thread Pool`: Создаем фиксированный набор потоков при старте приложения и используем их для выполнения всех задач. Это позволяет:
- Исключить накладные расходы на создание/уничтожение потоков для каждой задачи
- Контролировать общее количество потоков в приложении
- Улучшить использование кэша процессора (потоки долгоживущие)
- Упростить управление ресурсами

### 2. Структура `Thread Pool`
Типичный `thread pool` состоит из следующих компонентов:
1. Очередь задач (`Task Queue`)
- Назначение: Хранит задачи, ожидающие выполнения.
- Требования: Должна быть потокобезопасной (`thread-safe`), поддерживать операции добавления и извлечения задач из нескольких потоков.
- Реализация: Обычно блокирующая очередь на основе `std::queue`, защищенная мьютексом и `condition variable`.
```cpp
template<typename T>
class UnboundedBlockingQueue {
    std::queue<T> queue_;
    std::mutex mtx_;
    std::condition_variable not_empty_;
    bool cancelled_ = false;
    
public:
    void Push(T value) {
        std::lock_guard guard{mtx_};
        queue_.push(std::move(value));
        not_empty_.notify_one();  // Будим один ждущий воркер
    }
    
    std::optional<T> Pop() {
        std::unique_lock lock{mtx_};
        // Ждем, пока не появится задача или пул не остановят
        not_empty_.wait(lock, [this] {
            return !queue_.empty() || cancelled_;
        });
        
        if (queue_.empty()) return std::nullopt;
        
        T value = std::move(queue_.front());
        queue_.pop();
        return value;
    }
    
    void Cancel() {
        std::lock_guard guard{mtx_};
        cancelled_ = true;
        not_empty_.notify_all();  // Будим всех воркеров для завершения
    }
};
```
2. Рабочие потоки (`Worker Threads`)
- Назначение: Исполняют задачи из очереди.
- Количество: Фиксировано при создании пула.
- Логика работы: Бесконечный цикл, в котором поток:
    1. Извлекает задачу из очереди (блокируется, если очередь пуста)
    2. Выполняет задачу
    3. Возвращается к шагу 1
```cpp
void RunWorker() {
    while (auto task = queue_.Pop()) {
        try {
            (*task)();  // Выполняем задачу
        } catch (...) {
            // Обработка исключений (обычно логирование)
        }
    }
}
```
3. Интерфейс управления
- `Submit(Task task)` — добавляет задачу в очередь.
- `Stop() / деструктор` — останавливает пул: помечает очередь как отмененную, будит все потоки, дожидается их завершения.
- `Конструктор` — создает указанное количество рабочих потоков.

Полная структура `Thread Pool` (из лекции):
```cpp
class ThreadPool {
public:
    using Task = std::function<void()>;
    
    ThreadPool(size_t thread_count) {
        while (thread_count-- > 0) {
            workers_.emplace_back([this] { RunWorker(); });
        }
    }
    
    ~ThreadPool() { Stop(); }
    
    void Submit(Task task) {
        queue_.Push(std::move(task));
    }
    
    void Stop() {
        queue_.Cancel();
        for (auto& worker : workers_) {
            worker.join();
        }
        workers_.clear();
    }
    
private:
    std::vector<std::thread> workers_;
    UnboundedBlockingQueue<Task> queue_;
};
```

Важные аспекты реализации:
1. Обработка исключений: Задачи-функции могут бросать исключения. `Thread pool` должен их корректно обрабатывать (обычно логировать), чтобы исключение из одной задачи не приводило к падению всего рабочего потока.
2. `Graceful shutdown`: При остановке пула нужно:
    - Запретить добавление новых задач
    - Дождаться завершения уже выполняющихся задач
    - Корректно завершить все рабочие потоки
3. Ограничение размера очереди: В реализации выше очередь неограниченная (`unbounded`). В реальных системах часто делают `bounded` очередь для контроля использования памяти.

### 3. Выбор оптимального количества потоков
Выбор количества потоков в пуле критически важен для производительности. Неправильный выбор может привести к:
- Недоиспользованию CPU (слишком мало потоков)
- Чрезмерному переключению контекста (слишком много потоков)
- Исчерпанию памяти (каждый поток имеет стек)

Факторы, влияющие на оптимальное количество:
1. Тип задач:
    - CPU-bound задачи (вычислительные): ограничиваются количеством ядер CPU.
    - I/O-bound задачи (ожидание диска, сети): могут эффективно использовать больше потоков, так как потоки часто простаивают в ожидании.
2. Характеристики оборудования:
    - Количество CPU ядер (физических и логических).
    - Наличие hyper-threading (SMT).
    - Размер кэшей процессора.
3. Архитектура приложения:
    - Наличие других пулов потоков в системе.
    - Использование асинхронного I/O.
    - Требования к latency (задержкам) и throughput (пропускной способности).

#### Практические рекомендации:
1. Формула для CPU-bound задач:
```cpp
// Обычно берут количество логических процессоров
size_t optimal_threads = std::thread::hardware_concurrency();

// Или немного больше для компенсации простоев
size_t threads = std::thread::hardware_concurrency() + 1;
```
2. Для I/O-bound задач:
```cpp
// Эмпирическое правило Little's Law
// threads = (время_ожидания + время_обработки) / время_обработки

// На практике часто используют:
size_t threads = 2 * std::thread::hardware_concurrency();

// Или настраивают экспериментально под конкретную нагрузку
```
3. Для смешанной нагрузки:
```cpp
// Разделение на разные пулы
ThreadPool cpu_pool(std::thread::hardware_concurrency());
ThreadPool io_pool(4 * std::thread::hardware_concurrency());
```
4. Динамическая настройка (advanced):
    - Современные реализации thread pool (например, в Java ForkJoinPool) могут динамически адаптировать количество активных потоков.
    - Можно реализовать механизм, который мониторит загрузку CPU и длину очереди, адаптивно изменяя количество потоков.

Эмпирический подход:
- Начните с: std::thread::hardware_concurrency() для CPU-bound или 2 * hardware_concurrency() для I/O-bound.
- Проведите нагрузочное тестирование с разным количеством потоков.
- Измеряйте метрики: throughput, latency, использование CPU.
- Постройте график производительности от количества потоков — обычно есть точка, после которой добавление потоков не дает прироста или даже ухудшает производительность.

Пример для разных сценариев:
```cpp
// Веб-сервер с блокирующим I/O
ThreadPool server_pool(100);  // Много потоков для одновременных подключений

// Вычислительный pipeline
ThreadPool compute_pool(std::thread::hardware_concurrency());

// GUI приложение
ThreadPool gui_pool(4);  // Несколько потоков для фоновых задач
```

### 4. Сравнение с другими подходами
Параллельные алгоритмы STL:
```cpp
std::for_each(std::execution::par, begin, end, func);
```
Проблемы: Не контролируется количество потоков, создаются временные потоки на каждую операцию.

Решение в C++17: `std::execution::par` использует внутренние механизмы, но контроль ограничен.

Асинхронное программирование / корутины:
- Плюсы: Меньше накладных расходов, лучше масштабируются.
- Минусы: Сложнее в освоении, требуют поддержки языка/библиотек.

Компромисс: `Thread pool` часто используется как бэкенд для асинхронных операций.

### 5. Резюме
- `Thread pool` — это паттерн, при котором фиксированный набор потоков заранее создается и используется для выполнения асинхронных задач.
- Структура: Очередь задач + рабочие потоки + интерфейс управления.
- Преимущества: Исключение накладных расходов на создание потоков, контроль за количеством потоков, лучшее использование кэша.
- Выбор количества потоков:
    - Для CPU-bound: ≈ количество логических ядер CPU.
    - Для I/O-bound: в 2-10 раз больше, зависит от времени ожидания.
    - Всегда тестируйте под конкретную нагрузку.
- `Thread pool` — базовый строительный блок многопоточных приложений, на основе которого строятся более сложные системы (асинхронные фреймворки, акторные модели).

Золотое правило: Измеряйте производительность, а не угадывайте оптимальные параметры. Современные системы мониторинга (perf, Prometheus, Grafana) позволяют точно определить оптимальное количество потоков для конкретного приложения.

---

## Билет №12: Базовый `lock-free` код. `std::atomic`, проблемы при реализации `lock-free stack`. `ABA` в `lock-free stack`.

`Lock-free` программирование — это подход к написанию многопоточного кода, при котором прогресс системы гарантируется за счет того, что хотя бы один поток всегда продвигается вперёд, даже если другие потоки приостановлены. Это более сложная, но часто более эффективная альтернатива использованию мьютексов.

### 1. Базовый `lock-free` код и `std::atomic`
#### Что такое `std::atomic`?
`std::atomic` — это шаблонный класс, предоставляющий атомарные (неделимые) операции над типами данных. Атомарность гарантирует, что операция выполняется полностью без возможности прерывания другим потоком.
Базовые операции:
```cpp
#include <atomic>

std::atomic<int> x;

// Запись с барьером памяти
x.store(42, std::memory_order_seq_cst);

// Чтение с барьером памяти
int value = x.load(std::memory_order_seq_cst);

// Атомарный обмен
int old = x.exchange(42);

// Сравнение и обмен (CAS) - фундаментальная операция lock-free
int expected = 10;
bool success = x.compare_exchange_weak(expected, 42);
// Если x == expected, то x = 42 и success = true
// Иначе expected = текущее значение x и success = false
```

#### Зачем нужны атомики, если есть мьютексы?
Плюсы атомиков:
- Меньше инструкций: Атомарные операции часто реализуются одной инструкцией процессора (например, lock cmpxchg на x86).
- Отсутствие блокировок: Потоки не переходят в состояние ожидания ядра ОС.
- Предсказуемое время выполнения: Атомарные операции имеют детерминированную стоимость.
- Устойчивость к `deadlock`: Нет взаимных блокировок.

Минусы атомиков:
- Сложность программирования: Легко допустить тонкие ошибки.
- Ограниченные типы: Не все типы могут быть атомарными.
- Проблема `ABA`: Специфическая проблема `lock-free` алгоритмов.

Важно: Атомики не всегда быстрее мьютексов! В реальных тестах простые мьютексы часто показывают сравнимую или лучшую производительность на низкой конкуренции. Атомики выигрывают при высокой конкуренции многих потоков.

Пример: `SpinLock` на атомиках (из лекции):
```cpp
class SpinLock {
public:
    void lock() {
        // exchange возвращает старое значение и записывает true
        while (locked_.exchange(true, std::memory_order_acquire)) {
            // АКТИВНОЕ ОЖИДАНИЕ (busy-waiting)
            // В реальном коде здесь часто используют std::this_thread::yield()
            // или паузу процессора (__mm_pause())
        }
    }
    
    void unlock() {
        locked_.store(false, std::memory_order_release);
    }
    
private:
    std::atomic<bool> locked_ = false;
};
```

#### Lock-free vs Wait-free
`Lock-free`: Гарантируется, что хотя бы один поток делает прогресс. Другие могут "голодать".

`Wait-free`: Гарантируется, что каждый поток завершит свою операцию за ограниченное число шагов.

`Obstruction-free`: Слабее `lock-free` - прогресс гарантируется только если нет конфликтов.

### 2. Проблемы при реализации `lock-free stack`
Реализация `lock-free стека` — классическая задача, демонстрирующая сложности `lock-free` программирования.

Наивная попытка реализации:
```cpp
template<typename T>
class LockFreeStack {
    struct Node {
        T data;
        Node* next;
    };
    
    std::atomic<Node*> head_ = nullptr;
    
public:
    void push(const T& data) {
        Node* new_node = new Node{data, nullptr};
        // ПРОБЛЕМА: между чтением head и записью другой поток может изменить стек
        new_node->next = head_.load();
        head_.store(new_node);  // Data race!
    }
    
    bool pop(T& result) {
        Node* old_head = head_.load();
        if (!old_head) return false;
        // ПРОБЛЕМА: другой поток мог уже удалить этот узел
        head_.store(old_head->next);  // Data race!
        result = old_head->data;
        delete old_head;  // Опасность: удаление shared узла
        return true;
    }
};
```

Основные проблемы:
- Гонки данных (`Data Races`): Между чтением и записью `head_` другие потоки могут изменить стек.
- Удаление разделяемой памяти: Нельзя просто удалить узел, так как другие потоки могут все еще иметь указатели на него.
- Проблема `ABA`: Самая коварная проблема `lock-free` алгоритмов.

Корректная реализация с использованием `CAS`:
```cpp
template<typename T>
class LockFreeStack {
    struct Node {
        T data;
        Node* next;
    };
    
    std::atomic<Node*> head_ = nullptr;
    
public:
    void push(const T& data) {
        Node* new_node = new Node{data, nullptr};
        new_node->next = head_.load(std::memory_order_relaxed);
        
        // CAS-цикл: пытаемся атомарно обновить head
        while (!head_.compare_exchange_weak(
            new_node->next,  // expected: текущее значение head
            new_node,        // desired: новый head
            std::memory_order_release,
            std::memory_order_relaxed)) {
            // Если другой поток изменил head, обновляем new_node->next
            // и пытаемся снова
        }
    }
    
    bool pop(T& result) {
        Node* old_head = head_.load(std::memory_order_relaxed);
        while (old_head && 
               !head_.compare_exchange_weak(
                   old_head,           // expected: текущий head
                   old_head->next,     // desired: следующий узел
                   std::memory_order_acquire,
                   std::memory_order_relaxed)) {
            // Если другой поток изменил head, обновляем old_head
            // и пытаемся снова
        }
        
        if (!old_head) return false;
        
        result = old_head->data;
        // ОПАСНОСТЬ: проблема ABA и безопасное удаление
        delete old_head;
        return true;
    }
};
```

Оставшиеся проблемы:
- Проблема `ABA` (см. ниже)
- Безопасное удаление памяти: Нельзя сразу удалять узел, так как другие потоки могут все еще читать его (проблема `read-after-free`)

### 3. Проблема `ABA` в `lock-free stack`
`ABA` проблема — это классическая проблема `lock-free` программирования, возникающая при использовании алгоритмов сравнения-и-обмена (`CAS`).

Суть проблемы:
- Поток A читает значение указателя (например, head = 0x1000)
- Поток A приостанавливается
- Поток B удаляет узел 0x1000, освобождает память
- Поток C выделяет новую память, которая получает тот же адрес 0x1000 (случайное совпадение или переиспользование памяти)
- Поток C добавляет новый узел по адресу 0x1000 в стек
- Поток A возобновляется, его CAS успешно выполняется, так как head все еще равен 0x1000

Проблема: Поток A думает, что стек не изменился, но на самом деле это совершенно другой узел!

Пример сценария `ABA`:
```cpp
// Исходное состояние: head -> A -> B -> C

// Поток 1 (пытается удалить A):
Node* old_head = head.load();  // old_head = 0x1000 (узел A)
// Приостанавливается

// Поток 2 полностью удаляет стек:
// 1. Удаляет A (адрес 0x1000 освобождается)
// 2. Удаляет B
// 3. Удаляет C

// Поток 3 создает новый узел:
Node* new_node = new Node;  // Случайно получает адрес 0x1000!
new_node->data = "X";
push(new_node);  // Теперь head = 0x1000 (но это уже другой узел!)

// Поток 1 возобновляется:
// CAS: head (0x1000) сравнивается с old_head (0x1000) -> УСПЕХ!
// Но теперь head->next указывает в никуда (или на мусор)!
```
Последствия `ABA`:
- Повреждение структуры данных: Указатели могут указывать на освобожденную или перезаписанную память.
- Утечки памяти: Двойное освобождение или потерянные узлы.
- Неопределенное поведение: Чтение мусорных данных.

Решение проблемы `ABA`:
1. Использование счетчиков версий (tagged pointers):
```cpp
template<typename T>
class LockFreeStack {
    struct Node {
        T data;
        Node* next;
    };
    
    // Используем пару (указатель, счетчик)
    struct CountedNodePtr {
        Node* ptr;
        uint64_t count;
    };
    
    std::atomic<CountedNodePtr> head_;
    
public:
    void push(const T& data) {
        Node* new_node = new Node{data, nullptr};
        CountedNodePtr old_head = head_.load(std::memory_order_relaxed);
        
        do {
            new_node->next = old_head.ptr;
            CountedNodePtr new_head{new_node, old_head.count + 1};
        } while (!head_.compare_exchange_weak(
            old_head, new_head,
            std::memory_order_release,
            std::memory_order_relaxed));
    }
};
```
Принцип: К каждому указателю добавляем счетчик, который увеличивается при каждой операции. Даже если адрес совпадет, счетчик будет разный, и CAS не сработает.

2. Сборщик мусора (`hazard pointers`, `epoch-based reclamation`):
```cpp
// Hazard pointers - техника, при которой потоки объявляют,
// какие указатели они используют в данный момент
class HazardPointer {
    // Каждый поток регистрирует указатели, которые он читает
    // Удаление откладывается, пока на узел есть hazard pointers
};

// Использование:
bool pop(T& result) {
    Node* old_head;
    do {
        old_head = head_.load();
        // Регистрируем указатель как используемый
        hp.retire(old_head);
    } while (!head_.compare_exchange_weak(old_head, old_head->next));
    
    // Отложенное удаление
    hp.reclaim_later(old_head);
    return true;
}
```
3. `Reference counting` (с подсчетом ссылок):
```cpp
template<typename T>
class LockFreeStack {
    struct Node {
        std::atomic<int> ref_count;
        T data;
        Node* next;
    };
    
    // Увеличиваем счетчик при доступе к узлу
    // Удаляем только когда счетчик = 0
};
```
4. Дескрипторы операций (`operation descriptors`):
Более сложная техника, где каждая операция записывается в общую память перед выполнением.

### 4. Практические рекомендации
- Избегайте `lock-free` кода, если нет четких требований к производительности и `latency`.
- Используйте готовые реализации: `std::atomic`, `concurrent_queue` из `TBB`, `folly::AtomicHashMap`.
- Всегда тестируйте на различных архитектурах и с разным количеством потоков.
- Помните о `memory order`: По умолчанию используйте `memory_order_seq_cst`, ослабляйте барьеры только при понимании последствий.
- Профилируйте: `Lock-free` код не всегда быстрее `lock-based`.

Когда использовать `lock-free`:
- Высокочастотные операции (миллионы в секунду)
- Критичные по `latency` системы (`high-frequency trading`)
- Избегание `priority inversion` в `real-time` системах
- Когда блокировки становятся узким местом

Когда НЕ использовать lock-free:
- Низкая конкуренция (мало потоков)
- Сложные структуры данных
- Когда важна простота поддержки кода
- Если нет опыта в многопоточном программировании

### 5. Резюме
- `std::atomic` предоставляет атомарные операции, но не гарантирует лучшую производительность чем мьютексы.
- `Lock-free` алгоритмы сложны в реализации и требуют глубокого понимания многопоточности.
- `CAS` (`compare-and-swap`) — фундаментальная операция для `lock-free` программирования.
- Проблема `ABA` возникает, когда указатель освобождается и переиспользуется, а `CAS` не может отличить старый и новый узел.
- Решение `ABA`: `tagged pointers`, `hazard pointers`, `reference counting`.
- Правило: "Если вы думаете, что вам нужен `lock-free` код, скорее всего, вы ошибаетесь. Но если он действительно нужен, будьте готовы к сложностям."

Важно: Современные языки (Rust, Go) и библиотеки (Facebook Folly, Intel TBB) предоставляют готовые безопасные реализации lock-free структур данных, которые предпочтительнее собственных реализаций.

---

## Билет №13: Виды `userspace` корутин: `stackful` vs `stackless`. Причины появления `userspace scheduler`. Базовый интерфейс корутин из C++20.

`Корутины (coroutines)` — это обобщение подпрограмм (функций), которые могут приостанавливать своё выполнение и возобновлять его позже. В отличие от потоков ОС, переключение между корутинами происходит в пространстве пользователя (`userspace`) без участия ядра ОС, что делает их чрезвычайно легковесными.

### 1. Виды `userspace` корутин: `stackful` vs `stackless`
Корутины делятся на два основных типа по способу хранения своего состояния:
#### `Stackful` корутины
- Определение: Корутины, которые имеют собственный стек (аналогично потокам ОС).
- Характеристики:
    - Полный стек: Каждая корутина имеет отдельный регистровый контекст и стек вызовов.
    - Можно приостановить из любой вложенной функции: Приостановка возможна не только из самой корутины, но и из любой функции, которую она вызывает.
    - Более гибкие: Напоминают легковесные потоки (`green threads`).
    - Большие накладные расходы: Требуют выделения стека (обычно несколько КБ/МБ).
- Примеры реализаций:
    - `Boost.Coroutine` (старая версия)
    - `Goroutines` в `Go` (хотя технически это больше, чем корутины)
    - `Файберы` (`fibers`) в `Windows`

Псевдокод:
```cpp
// Stackful корутина может быть приостановлена из глубоко вложенной функции
void deep_function(stackful_coroutine& co) {
    // ...
    co.yield();  // Приостановка из вложенного вызова
    // ...
}

void my_coroutine() {
    deep_function(current_coroutine());
    // После возобновления продолжим отсюда
}
```

#### `Stackless` корутины
- Определение: Корутины, которые не имеют собственного стека и используют стек вызывающей стороны.
- Характеристики:
    - Разделяемый стек: Состояние хранится в отдельной структуре (обычно в куче), но вызовы функций используют стек того, кто возобновляет корутину.
    - Можно приостановить только из самой корутины: Приостановка возможна только в теле корутины или в функциях, которые "знают" о том, что вызываются из корутины.
    - Более эффективные: Меньший `overhead` по памяти, быстрее переключение.
    - Ограниченные: Не могут быть приостановлены из произвольной вложенной функции.
- Примеры реализаций:
    - `C++20` корутины (стандартные)
    - `Python` генераторы (`yield`)
    - `C# async/await` (технически `stackless`)
    - `Kotlin coroutines` (по умолчанию `stackless`)

Псевдокод:
```cpp
stackless_coroutine<int> my_coroutine() {
    // Можно приостановить здесь
    co_yield 42;
    
    // НО НЕЛЬЗЯ приостановить из вызываемой функции:
    // helper_function();  // Если helper_function вызовет co_yield - ошибка компиляции
    
    co_return 100;
}
```

### 2. Причины появления `userspace scheduler`
`Userspace scheduler` (планировщик в пространстве пользователя) — это компонент, который управляет выполнением корутин без участия ядра ОС.

Проблемы, которые решает userspace scheduler:
1. Высокая стоимость потоков ОС:
    - Создание потока: ~1-10 микросекунд
    - Переключение контекста: ~1-100 микросекунд
    - Память на стек: ~1-8 МБ
    - Корутины: создание за наносекунды, переключение за десятки наносекунд, память ~1-10 КБ
2. Неэффективность при большом количестве I/O операций:
    - Веб-серверы, СУБД, микросервисы обрабатывают десятки тысяч одновременных соединений
    - Потоков ОС на такое количество не хватает (ограничение планировщиком ОС)
    - Корутины позволяют иметь миллионы "одновременных" задач
3. Контроль над планированием:
    - Планировщик ОС — "чёрный ящик", работает по своим алгоритмам (CFS в Linux)
    - Userspace scheduler позволяет:
        - Приоритизировать задачи по бизнес-логике
        - Гарантировать fair scheduling
        - Реализовывать специализированные политики (deadline, round-robin)
4. Устранение contention на блокировках:
    - Мьютексы ядра — bottleneck при высокой конкуренции
    - Корутины + userspace scheduler позволяют использовать cooperative multitasking, где задачи добровольно уступают управление
5. Улучшение cache locality:
    - Планировщик в userspace может учитывать топологию процессора
    - Может привязывать корутины к конкретным ядрам
    - Сохранять данные в кэшах процессора

Архитектура типичной системы с корутинами:
```text
┌─────────────────────────────────────────────┐
│           Приложение                        │
├─────────────────────────────────────────────┤
│      Userspace Scheduler (кооперативный)    │
│    ┌─────────┐ ┌─────────┐ ┌─────────┐     │
│    │Корутина1│ │Корутина2│ │Корутина3│ ... │
│    └─────────┘ └─────────┘ └─────────┘     │
├─────────────────────────────────────────────┤
│         Библиотека корутин (C++20)          │
├─────────────────────────────────────────────┤
│    Потоки ОС (1..N, где N = #ядер CPU)      │
├─────────────────────────────────────────────┤
│              Ядро ОС                         │
└─────────────────────────────────────────────┘
```

Пример: Веб-сервер на корутинах
```cpp
// Без корутин (потоки ОС)
void handle_client(Socket socket) {
    // Блокирующий read - поток ОС засыпает
    auto data = socket.read();  // Дорого!
    process(data);
    socket.write(response);
}

// С корутинами
coroutine<void> handle_client(Socket socket) {
    // Неблокирующий read - корутина приостанавливается
    auto data = co_await socket.async_read();  // Дешево!
    process(data);
    co_await socket.async_write(response);
}
```

Преимущества подхода:
- Масштабируемость: 10,000+ одновременных соединений
- Эффективность: Нагрузка CPU близка к 100% на полезной работе
- Предсказуемость: Детерминированное планирование

### 3. Базовый интерфейс корутин из C++20
C++20 вводит `stackless` корутины как языковую фичу. Это не библиотека, а изменения в самом языке.

Ключевые компоненты:
1. Ключевые слова:
    - `co_await` — приостановка корутины до готовности значения
    - `co_yield` — возврат значения и приостановка (для генераторов)
    - `co_return` — завершение корутины с возвратом значения
2. Типы корутин:
    - Генераторы (generators): Последовательная выдача значений
    - Асинхронные задачи (tasks): Асинхронные вычисления
    - Ленивые вычисления (lazy): Вычисления по требованию

Минимальный пример корутины-генератора:
```cpp
#include <coroutine>
#include <iostream>

// Тип-возвращаемое значение корутины
struct Generator {
    struct promise_type {
        int current_value;
        
        // Вызывается при первом вызове корутины
        Generator get_return_object() {
            return Generator{std::coroutine_handle<promise_type>::from_promise(*this)};
        }
        
        // Начальное состояние - приостановлена
        std::suspend_always initial_suspend() { return {}; }
        
        // После завершения - приостановлена (чтобы можно было прочитать результат)
        std::suspend_always final_suspend() noexcept { return {}; }
        
        void return_void() {}
        void unhandled_exception() { std::terminate(); }
        
        // Вызывается при co_yield
        std::suspend_always yield_value(int value) {
            current_value = value;
            return {};
        }
    };
    
    std::coroutine_handle<promise_type> handle;
    
    // Деструктор
    ~Generator() {
        if (handle) handle.destroy();
    }
    
    // Получить следующее значение
    bool next() {
        if (!handle.done()) {
            handle.resume();
            return !handle.done();
        }
        return false;
    }
    
    // Текущее значение
    int value() const {
        return handle.promise().current_value;
    }
};

// Сама корутина
Generator range(int from, int to) {
    for (int i = from; i < to; ++i) {
        co_yield i;  // Возвращаем значение и приостанавливаемся
    }
}

int main() {
    auto gen = range(1, 5);
    
    while (gen.next()) {
        std::cout << gen.value() << " ";  // 1 2 3 4
    }
    std::cout << std::endl;
    
    return 0;
}
```

Базовый интерфейс:
1. `std::coroutine_handle<Promise>` — дескриптор корутины для управления
```cpp
auto handle = std::coroutine_handle<Promise>::from_promise(promise);
handle.resume();  // Возобновить выполнение
handle.destroy(); // Уничтожить корутину
bool done = handle.done(); // Завершена ли корутина
```
2. Типы приостановки:
    - `std::suspend_always` — всегда приостанавливать
    - `std::suspend_never` — никогда не приостанавливать
3. `promise_type` — интерфейс, который должен быть определен в типе, возвращаемом корутиной:
```cpp
struct MyReturnType {
    struct promise_type {
        MyReturnType get_return_object();
        std::suspend_always initial_suspend();
        std::suspend_always final_suspend() noexcept;
        void return_void();  // или return_value(T)
        void unhandled_exception();
        // Для co_yield:
        std::suspend_always yield_value(T);
    };
};
```

Пример асинхронной задачи:
```cpp
#include <coroutine>
#include <future>
#include <iostream>

template<typename T>
struct Task {
    struct promise_type {
        T value;
        std::exception_ptr exception;
        
        Task get_return_object() {
            return Task{std::coroutine_handle<promise_type>::from_promise(*this)};
        }
        
        std::suspend_always initial_suspend() { return {}; }
        std::suspend_always final_suspend() noexcept { return {}; }
        
        void return_value(T val) { value = std::move(val); }
        void unhandled_exception() { exception = std::current_exception(); }
    };
    
    std::coroutine_handle<promise_type> handle;
    
    ~Task() { if (handle) handle.destroy(); }
    
    T get() {
        handle.resume();
        if (handle.promise().exception)
            std::rethrow_exception(handle.promise().exception);
        return std::move(handle.promise().value);
    }
};

Task<int> compute_answer() {
    co_return 42;  // Асинхронное вычисление
}

int main() {
    auto task = compute_answer();  // Не начинает вычисление сразу
    std::cout << task.get() << std::endl;  // 42
    return 0;
}
```

Преимущества C++20 корутин:
- Интеграция с языком: Не нужны макросы или кодогенерация
- Эффективность: `Zero-overhead` абстракция
- Гибкость: Можно строить различные абстракции поверх

Недостатки/сложности:
- Низкоуровневый API: Нужно писать много `boilerplate` кода
- Нет готовых типов в стандарте: `std::generator` и `std::task` будут в C++23/26
- Сложность отладки: Новый паттерм выполнения

### 4. Резюме
1. `Stackful` vs `Stackless`:
    - `Stackful` — имеют свой стек, можно приостанавливать из любого места, но дороже.
    - `Stackless` — используют стек вызывающего, приостанавливаются только из тела корутины, но эффективнее. C++20 использует `stackless`.
2. Userspace scheduler появился для:
    - Эффективной работы с миллионами одновременных операций `I/O`
    - Избегания накладных расходов потоков ОС
    - Полного контроля над планированием выполнения
    - Улучшения `cache locality` и уменьшения `contention`
3. Базовый интерфейс C++20 корутин:
    - Ключевые слова: `co_await`, `co_yield`, `co_return`
    - Тип должен содержать `promise_type` с обязательными методами
    - Управление через `std::coroutine_handle`
    - Пока нет готовых высокоуровневых типов в стандарте (ждут C++23/26)

Практический совет: Для production кода используйте библиотеки, которые предоставляют готовые абстракции поверх C++20 корутин: `cppcoro`, `Boost.Coroutine2`, или фреймворки типа `Seastar`. Прямое использование `low-level API C++20 корутин` оправдано только при создании таких библиотек.
