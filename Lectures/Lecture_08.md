# Лекция №8 (11/11/2025). Многопоточность
## Немного истории
Сначала были одноядерные процессоры, которые обращались напрямую к RAM.

Но этого перестало хватать, так как RAM была далеко (чисто физически, по расстоянию) от ядра процессора. Добавили кэш процессора. Ныне их известно три: L1, L2, L3 - от самого быстрого, к самому медленному.

В нулевых уже задумались о том, что производительности одного ядра не хватает. Стали делать материнские платы, на которые помещались два процессора, чтобы в итоге получить два ядра.

Примерно в 2005 году появились первые многоядерные процессоры.

Так или иначе, сейчас всё завязано на работе с кэшэм, ибо доступ в память, произвольное чтение из неё, крайне дорогое. Частота процессоров в наше время может достигать 4ГГц и, возможно, более. То есть условно один такт - это 1/4 милисекунды. В то же время операция чтения из памяти занимает порядка 70 милисекунд.

Операционная система - это абстракция над железом для удобства разработчиков приложений (ибо можно с ума сойти вечно реализовывать работу с кучей ядер и прочим).

## C++ threads
В С++11 появился уницифицированный инструментарий работы с потоками. Раньше с потоками работали средствами операционной системы.

Механизм для запуска потоков: `std::thread`

Примитивы для организации многопоточных вычислений: `std::mutex`, `std::atomic`, `std::condition_variable`

Если интересует многопоточка - приходите на курс Ромы Липовского.

## Давайте смотреть примеры
```cpp
#include <iostream>
#include <thread>

int main() {
    std::thread t1{[] {
        std::cout << "Hello, ";
    }};
    std::thread t2{[] {
        std::cout << "threads!";
    }};
}
```
Такой код мягко говоря не корректный, он то выводит `Hello`, то `Hello, threads!`, то вообще ничего не выводит, и всегда сигнализирует о `SIGABRT`.

Потоки нужно либо джойнить, либо детачить:
```cpp
#include <iostream>
#include <thread>

int main() {
    std::thread t1{[] {
        std::cout << "Hello, ";
    }};
    std::thread t2{[] {
        std::cout << "threads!";
    }};

    t1.join();
    t2.join();
}
```
`join()` останавливает текущий поток, пока не закончится ожидаемый. А метод `detach()` использовать не надо.

Теперь ошибок нет, однако, выводятся они как хотят (ну надо в каждый добавить `sleep(1)`, чтобы сработало): то в одном порядке, то в другом. Эти два потока никак не связаны друг с другом, и здесь вскрывает основная проблема многопоточки: `Race Condition`. 

Добавим точку синхронизации, чтобы получать на выходе `Hello, threads!`:
```cpp
#include <iostream>
#include <thread>

int main() {
    std::thread t1{[] {
        std::cout << "Hello, ";
    }};
    std::thread t2{[&] {
        t1.join();
        std::cout << "threads!";
    }};

    t2.join();
}
```
`Race Condition` - не UB. Вообще говоря это ситуация, когда для двух операций в разных потоках нет условия `happens before`, то есть мы не можем сказать, доказать, что выполнится раньше.

Однако, есть страшные проявления `Race Condition`, которые являются UB. Например, `Data Race`. Это гонка по данным. То есть два потока меняют какие-то данные, будучи не синхронизированными между собой. В нашем примере проблема в том, что нельзя из двух разных потоков писать в буффер.

В C++20 появился `std::jthread()`. Он позволяет не писать `join()`:
```cpp
#include <iostream>
#include <thread>

int main() {
    std::jthread t1{[] {
        std::cout << "Hello, ";
    }};
    std::jthread t2{[&] {
        std::cout << "threads!";
    }};
}
```
Он выполняет `join()` в деструкторе потока.

Есть метод `joinable()`, который проверяет, позвали ли `join()` на этот поток. Впринципе `join()` обязательная штука, это освобождение ресурсов, как `delete` на указатель. Выглядит это обычно так:
```cpp
if (t1.joinable()) {
    t1.join();
}
```

## Синхронизация
Лучше всего ничего не синхронизировать. Чем больше у вас потоков и взаимосвязей между ними, тем менее эффективен ваш код.

Небольшое отвлечение: вместо лямбды можно передавать целую функцию. Например:
```cpp
#include <iostream>
#include <thread>

void Run(const char* name) {
    std::cout << "Hello, " << name;
}

int main() {
    std::thread t1(Run, "world");

    t1.join();
}
```

Вот отличный пример `Data Race`:
```cpp
#include <iostream>
#include <thread>

int x;

void Run(const char* name) {
    x = 2;
}

int main() {
    std::jthread t1(Run, "world");
    std::jthread t2([&] {
        x = 3;
    })
}
```

Но есть пример получше:
```cpp
#include <iostream>
#include <thread>

// #define int long long - ОСУЖДАЕМ)9))0)
int sum = 0;

void Run(const char* name) {
    for (/*volatile*/int i = 0; i < 1'000'000'000; ++i) {
        sum++;
    }
}

signed main() {
    std::jthread t1(Run, "world");
    std::jthread t2(Run, "world");
    std::jthread t3(Run, "world");
    std::jthread t4(Run, "world");

    t1.join();
    t2.join();
    t3.join();
    t4.join();
}
```
```
- А что за красивое слово Вы написали? volatile?
- А я его не написал, не знаю о чём вы.
```
В общем ожидаем мы тут 4 миллиарда, а получаем что-то странное, чуть больше 1 миллиарда. Проблема в атомарности операции. Атомарная операция, то есть неделимая. Мы не можем начать её выполнять, отвлечься на другую, и затем вернуться к исходной. То есть она выполняется целиком сразу. Операция присваивания - атомарная. А вот инкремент - нет. Тут две операции: сначала прочитать, затем прибавить число. Но на самом деле, возвращаясь в том числе к примеру выше: и то, и то - `Data Race`, но на уровне процессора они проявляются по-разному.
```
- Ну кстати, нам же не нужен идеально рабочий код. Нам нужен код, который просто больше всего выведет. 
  То есть порой можно допусть UB, если оно поможет нам.
- Вы так, это, в больнице скажите.
```

# std::mutex
Всё, конечно, замечательно, но складывается ощущение, что потоками пользоваться не возможно. Как жить? Есть две школы. Есть школа более общая, но более медленная. Это `std::mutex`. Мьютекс, или критическая секция. Как это работает?
```cpp
#include <iostream>
#include <thread>

int64_t sum = 0;
std::mutex mtx;

void Run(const char* name) {
    for (int i = 0; i < 1'000'000'000; ++i) {
        mtx.lock();
        sum++;
        mtx.unlock();
    }
}

int main() {
    std::jthread t1(Run, "world");
    std::jthread t2(Run, "world");
    std::jthread t3(Run, "world");
    std::jthread t4(Run, "world");

    t1.join();
    t2.join();
    t3.join();
    t4.join();
}
```
`lock()` говорит, что вы вошли в критическую секцию, и никто другой в неё войти не может. `unlock()` обратно его разблокирует. Если в одном потоке вы вошли в `lock()`, и есть вызов `lock()` в другом потоке, то другой поток будет дожидаться первого, пока тот не выйдет из критической секции. То есть как только вы вызвали `lock()` у вас появляется условие `happes before`, поскольку вы четко можете сказать как связаны несколько потоков между собой отношениями `happens before`.

Умное слово: `профилирование`. В Яндексе есть для этого инструмент `perforator`. Поможет узнать, где в многопоточке тратятся ресурсы, в каком количестве. Поэтому гадать не надо, надо пользоваться доступными инструментами, созданными для диагностики подобных проблем.

Надо помнить про кэш-линии... Понимал бы я ещё последние 10 минут лекции этой...
